# -*- coding: utf-8 -*-
"""Task 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rVb7h6zUuMbEcuV-gI6L5kXQdlsGbBnv

**Oasis** **Infobyte** **Internship**,**November**-**2023**

R Adarsh,Data Science intern

```
`# This is formatted as code`
```

**Iris Flower Clssification ML Project:**

Dataset : https://www.kaggle.com/datasets/saurabh00007/iriscsv

**Importing Important Libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
# %matplotlib inline
from matplotlib import style
from sklearn.datasets import load_iris
import pandas as pd

# Load the Iris dataset
iris = load_iris()

# Create a DataFrame using pandas
iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
iris_df['Species'] = iris.target_names[iris.target]
style.use('dark_background')

## Supress warnings
import warnings
warnings.filterwarnings("ignore")

"""Now, loading dataset given in task pdf into notebook

"""

iris_df =pd.read_csv('/content/Iris.csv')
print("The dataset is fetched successfully")

iris_df

"""**Data Exploration**"""

#check shape of data
iris_df.shape

#check basic information of data
iris_df.info()

#check statistical summary of data
iris_df.describe()

#check null values
iris_df.isnull().sum()

print("unique number of values in dataset species:",iris_df["Species"].nunique())
print("Unique Species in iris dataset:",iris_df["Species"].unique())

"""*   There are 3 species in iris dataset that is       **'Iris-setosa', 'Iris-versicolor', 'Iris-virginica'.**

**Exploratorty Data Analysis**

***Data Visualization***
"""

sns.pairplot(iris_df, hue = "Species",markers = "x")
plt.show()

"""

*   It shows that Iris-Setosa is seperated from both other species in all features..
"""

plt.figure(figsize=(15,5))
plt.subplot(1,2,1)
sns.scatterplot(x='SepalLengthCm',y='PetalLengthCm',data=iris_df,hue='Species')

plt.subplot(1,2,2)
sns.scatterplot(x='SepalWidthCm',y='PetalWidthCm',data=iris_df,hue='Species')

plt.show()

#Check correlation in Dataset
iris_df.corr()

#Use Heatmap to see correlation
plt.figure(figsize=(10,7))
sns.heatmap(iris_df.corr(),annot = True,cmap = "Oranges_r")
plt.show()

"""

*   In the above heatmap we can see petal length and petal width is highly correlated.
"""

#Check value counts
iris_df["Species"].value_counts().plot(kind="pie",autopct = "%1.1f%%",shadow=True, figsize=(5,5))
plt.title("Percentage values in each Species", fontsize = 12 , c = "g")
plt.ylabel("",fontsize=10,c="r")
plt.show()

"""

*   We can see all the  species has equal values in dataset
*   Iris-Setosa:50
*   Iris-Versicolor:50
*   Iris-Virginica:50



"""

sns.jointplot(data = iris_df , x = "SepalLengthCm", y = "SepalWidthCm" , size = 7 , hue = "Species")

plt.show()

sns.jointplot(data = iris_df , x = "PetalLengthCm", y = "PetalWidthCm" , size = 7 , hue = "Species")

plt.show()

print(iris_df.columns)

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(15, 5))

plt.subplot(2, 2, 1)
sns.barplot(x="Species", y="sepal length (cm)", data=iris_df, palette="coolwarm")
plt.title("Bar plot SepalLengthCm Vs Species")

plt.subplot(2, 2, 2)
sns.boxplot(x="Species", y="sepal length (cm)", data=iris_df, palette="coolwarm")
plt.title("Box plot SepalLengthCm Vs Species")

plt.subplot(2, 2, 3)
sns.barplot(x="Species", y="sepal length (cm)", data=iris_df, palette="coolwarm")
plt.title("Bar plot SepalLengthCm Vs Species")

plt.subplot(2, 2, 4)
sns.boxplot(x="Species", y="sepal length (cm)", data=iris_df, palette="coolwarm")
plt.title("Box plot SepalLengthCm Vs Species")

plt.show()

# plt.figure(figsize = (15,5))
# plt.subplot(2,2,1)
# sns.barplot(x = "Species",y = "SepalLengthcm", data=iris_df, palette=("coolwarm"))
# plt.title("Bar plot SepalLengthcm Vs Species")


# plt.subplot(2,2,2)
# sns.boxplot(x = "Species",y = "SepalLengthcm", data=iris_df, palette=("coolwarm"))
# plt.title("Bax-plot SepalLengthCm Vs Species")


# plt.subplot(2,2,3)
# sns.barplot(x = "Species",y = "SepalLengthCm", data=iris_df, palette=("coolwarm"))
# plt.title("Bar plot SepalLengthcm Vs Species")

# plt.subplot(2,2,4)
# sns.boxplot(x = "Species",y = "SepalLengthcm", data=iris_df, palette=("coolwarm"))
# plt.title("Bax-plot SepalLengthcm Vs Species")

# plt.show()

plt.figure(figsize=(20,15))
plt.subplot(2,2,1)
sns.distplot(iris_df["sepal length (cm)"],color="y").set_title("Sepal Length interval")

plt.subplot(2,2,2)
sns.distplot(iris_df["sepal width (cm)"],color="r").set_title("Sepal Width interval")

plt.subplot(2,2,3)
sns.distplot(iris_df["petal length (cm)"],color="g").set_title("Petal Length interval")

plt.subplot(2,2,4)
sns.distplot(iris_df["petal width (cm)"],color="b").set_title("Petal Width interval")

plt.show()

"""**Data Cleaning**"""

# change categorical Data into numerical value*
from sklearn.preprocessing import LabelEncoder
from sklearn.datasets import load_iris
iris=load_iris()
le = LabelEncoder()

iris_df["Species"] = le.fit_transform(iris_df["Species"])
iris_df.head()

iris_df['Species'].unique()

X = iris_df.iloc[:,[0,1,2,3]]
X.head()

y = iris_df.iloc[:, -1]
y.head()

print(X.shape)
print(y.shape)

"""**Model Building**

**Supervised Machine Learning**

Split data into Traning and Testing **Set**
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""**LOGISTIC** **REGRESSION**"""

from sklearn.linear_model import LogisticRegression
lr= LogisticRegression()

lr.fit(X_train, y_train)
print("Logistic regression successfully implemented")

y_pred = lr.predict(X_test)

#confusion Matrix
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
cm = confusion_matrix(y_test, y_pred)

print("Confusion Matrix:-")
print(cm)

accuracy = accuracy_score(y_test,y_pred)

print("accuracy is:-",accuracy*100)

print("Classification Report:-")
print(classification_report(y_test,y_pred))

"""**Random Forest Classifier**"""

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()

rfc.fit(X_train, y_train)
print("Random Forest Classifier successfully Implemented")

y_pred = rfc.predict(X_test)

#confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:- ")
print(cm)

"""**Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier

dtree = DecisionTreeClassifier()

dtree.fit(X_train, y_train)
print("Decision Tree Algorithm is successfully implemented.")

y_pred = dtree.predict(X_test)

#confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:- ")
print(cm)

#accuracy test
accuracy = accuracy_score(y_test, y_pred)

print("accuracy:- ", accuracy*100)

print("Classification Report:-")
print( classification_report(y_test, y_pred))

from sklearn.tree import plot_tree

# for visualizing the Decision Tree
feature = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']
classes = ['Iris-Setosa','Iris-Versicolor','Iris-Virginica']

plt.figure(figsize=(10,10))
plot_tree(dtree, feature_names = feature, class_names = classes, filled = True);

"""**Support Vector Machine**"""

from sklearn.svm import SVC
svc= SVC()

svc.fit(X_train, y_train)
print("Support vector classifier is successfully implemented")

y_pred = svc.predict(X_test)

#confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:- ")
print(cm)

#accuracy test
accuracy = accuracy_score(y_test,y_pred)

print("accuracy:- ", accuracy*100)

print("Classification Report:-")
print(classification_report(y_test, y_pred))

"""**K - NN classifier**"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors= 7)
knn.fit(X_train, y_train)


print("K-Nearest Neighbors classifier is successfully implemented")

y_pred = knn.predict(X_test)

#confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:- ")
print(cm)

#accuracy test
accuracy = accuracy_score(y_test,y_pred)

print("accuracy:- ", accuracy*100)

print("Classification Report:-")
print(classification_report(y_test, y_pred))

"""**Navie Bayes**"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(X_train, y_train)
print("Navie Bayes is successfully implemented")

y_pred = gnb.predict(X_test)

#confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:- ")
print(cm)

#accuracy test
accuracy = accuracy_score(y_test,y_pred)

print("accuracy:- ", accuracy*100)

print("Classification Report:-")
print(classification_report(y_test, y_pred))

"""**Result**

*   1.Accuracy of Logistic Regression:- 100%
*   2.Accuracy of Random Forest Classifier:- 100%
*   3.Accuracy of Decision Tree:- 100%
*   4.Accuracy of Support Vector Machine:- 100%
*   5.Accuracy of K-NN Classifier:- 100%
*   6.Accuracy of Naive Bayes:- 100%

**Test Model**
"""

input_data=(4.9,3.0,1.4,0.2)

#changing the input data to a array
input_data_as_nparray = np.asarray(input_data)

#reshape the data as we are predicting the Label for only the instance
input_data_reshaped = input_data_as_nparray.reshape(1,-1)

prediction = dtree.predict(input_data_reshaped)
print("The category is",prediction)

"""**Thank You!**"""